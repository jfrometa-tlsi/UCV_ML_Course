{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDF0nqFgbvis"
      },
      "source": [
        "## **Clase 10: Conexi√≥n a Gemini (Google) v√≠a API**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BpyoCHygcAow"
      },
      "source": [
        "### **Instalaci√≥n de librer√≠as**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TsXnoPI0bq_l",
        "outputId": "f970971b-b628-4ce5-b98a-a8a449ba70c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: google-genai in /usr/local/lib/python3.12/dist-packages (1.55.0)\n",
            "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from google-genai) (4.12.1)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from google-auth[requests]<3.0.0,>=2.14.1->google-genai) (2.43.0)\n",
            "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in /usr/local/lib/python3.12/dist-packages (from google-genai) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.9.0 in /usr/local/lib/python3.12/dist-packages (from google-genai) (2.12.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.28.1 in /usr/local/lib/python3.12/dist-packages (from google-genai) (2.32.4)\n",
            "Requirement already satisfied: tenacity<9.2.0,>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from google-genai) (9.1.2)\n",
            "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from google-genai) (15.0.1)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.11.0 in /usr/local/lib/python3.12/dist-packages (from google-genai) (4.15.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from google-genai) (1.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from google-genai) (1.3.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0.0,>=4.8.0->google-genai) (3.11)\n",
            "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-auth[requests]<3.0.0,>=2.14.1->google-genai) (6.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-auth[requests]<3.0.0,>=2.14.1->google-genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-auth[requests]<3.0.0,>=2.14.1->google-genai) (4.9.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.9.0->google-genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.9.0->google-genai) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.9.0->google-genai) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.28.1->google-genai) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.28.1->google-genai) (2.5.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-auth[requests]<3.0.0,>=2.14.1->google-genai) (0.6.2)\n"
          ]
        }
      ],
      "source": [
        "#Para entorno Colab\n",
        "!pip install google-genai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aemQnaKTcRiM"
      },
      "source": [
        "### **Configuraci√≥n inicial**\n",
        "### **üõ†Ô∏è Configuraci√≥n de tu Entorno de IA: Obtenci√≥n de API Key**\n",
        "\n",
        "Para interactuar con los modelos de lenguaje de √∫ltima generaci√≥n (como Gemini 1.5 Flash) desde Python, necesitamos una \"llave\" que nos identifique ante los servidores de Google. En esta sesi√≥n, utilizaremos el plan gratuito para desarrolladores.\n",
        "\n",
        "**Paso 1: Generar tu API Key**\n",
        "- Accede a [Google AI Studio](https://aistudio.google.com/).\n",
        "\n",
        "- Inicia sesi√≥n con tu cuenta de Google/Gmail.\n",
        "\n",
        "- En el panel lateral izquierdo, haz clic en el bot√≥n \"Get API key\".\n",
        "\n",
        "- Selecciona \"Create API key in new project\".\n",
        "\n",
        "- Copia la clave generada. Mant√©n esta clave en secreto; es personal y est√° vinculada a tu cuenta.\n",
        "\n",
        "**Paso 2: Configurar la clave en Google Colab (Opcional)**\n",
        "\n",
        "Para evitar escribir la clave directamente en el c√≥digo (una mala pr√°ctica de seguridad conocida como hardcoding), usaremos el sistema de \"Secrets\" de Colab:\n",
        "\n",
        "- En la barra lateral izquierda de este notebook, haz clic en el icono de la llave (üîë Secrets).\n",
        "\n",
        "- A√±ade un nuevo secreto con el nombre: GOOGLE_API_KEY.\n",
        "\n",
        "- Pega tu clave en el campo \"Value\".\n",
        "\n",
        "_Importante: Activa el interruptor de \"Notebook access\" para que el c√≥digo pueda leer la clave._"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKTbSqRKcxGq",
        "outputId": "2821805d-6b81-4a9c-b61d-240db33e4a70"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚ùå Error: No se encontr√≥ la clave 'GOOGLE_API_KEY' en los secretos de Colab.\n",
            "Por favor, revisa la gu√≠a anterior o establecela a continuaci√≥n\n",
            "‚úÖ Configuraci√≥n exitosa: API Key cargada correctamente desde la variable 'api_key_hard'.\n"
          ]
        }
      ],
      "source": [
        "#from google.colab import userdata # Descomentar esta l√≠nea si se est√° ejecutando en Google Colab\n",
        "from google import genai\n",
        "\n",
        "# Recuperar la clave desde los secretos de Colab\n",
        "try:\n",
        "    api_key = userdata.get('GOOGLE_API_KEY')\n",
        "    client = genai.Client(api_key=api_key)\n",
        "    print(\"‚úÖ Configuraci√≥n exitosa: API Key cargada correctamente desde los secretos de Colab.\")\n",
        "except Exception as e:\n",
        "    api_key = None\n",
        "    print(\"‚ùå Error: No se encontr√≥ la clave 'GOOGLE_API_KEY' en los secretos de Colab.\")\n",
        "    print(\"Por favor, revisa la gu√≠a anterior o establecela a continuaci√≥n\")\n",
        "api_key_hard = \"AIzaSyAKgJfO7FLFyq4lyurFVaGLHGJGW8uQlEY\" #Se puede configurar directamente aqu√≠\n",
        "if api_key_hard is not None and api_key is None:\n",
        "    api_key = api_key_hard\n",
        "    client = genai.Client(api_key=api_key)\n",
        "    print(\"‚úÖ Configuraci√≥n exitosa: API Key cargada correctamente desde la variable 'api_key_hard'.\")\n",
        "elif api_key_hard is not None and api_key is not None:\n",
        "    print(\"‚ùå Error: No se encontr√≥ la clave 'GOOGLE_API_KEY' en los secretos de Colab ni en la variable 'api_key_hard'.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2y37Wm1seUQ3"
      },
      "source": [
        "### **Viendo modelos disponibles en Gemini**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ImOtDeXAb2WU",
        "outputId": "03ad9865-2a28-45a5-ec91-b5b03540166e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "List of models that support generateContent:\n",
            "\n",
            "models/gemini-2.5-flash\n",
            "models/gemini-2.5-pro\n",
            "models/gemini-2.0-flash\n",
            "models/gemini-2.0-flash-001\n",
            "models/gemini-2.0-flash-lite-001\n",
            "models/gemini-2.0-flash-lite\n",
            "models/gemini-exp-1206\n",
            "models/gemini-2.5-flash-preview-tts\n",
            "models/gemini-2.5-pro-preview-tts\n",
            "models/gemma-3-1b-it\n",
            "models/gemma-3-4b-it\n",
            "models/gemma-3-12b-it\n",
            "models/gemma-3-27b-it\n",
            "models/gemma-3n-e4b-it\n",
            "models/gemma-3n-e2b-it\n",
            "models/gemini-flash-latest\n",
            "models/gemini-flash-lite-latest\n",
            "models/gemini-pro-latest\n",
            "models/gemini-2.5-flash-lite\n",
            "models/gemini-2.5-flash-image\n",
            "models/gemini-2.5-flash-preview-09-2025\n",
            "models/gemini-2.5-flash-lite-preview-09-2025\n",
            "models/gemini-3-pro-preview\n",
            "models/gemini-3-flash-preview\n",
            "models/gemini-3-pro-image-preview\n",
            "models/nano-banana-pro-preview\n",
            "models/gemini-robotics-er-1.5-preview\n",
            "models/gemini-2.5-computer-use-preview-10-2025\n",
            "models/deep-research-pro-preview-12-2025\n",
            "------------------------------------------------------------\n",
            "List of models that support embedContent:\n",
            "\n",
            "models/embedding-001\n",
            "models/text-embedding-004\n",
            "models/gemini-embedding-001\n"
          ]
        }
      ],
      "source": [
        "print(\"List of models that support generateContent:\\n\")\n",
        "for m in client.models.list():\n",
        "    for action in m.supported_actions:\n",
        "        if action == \"generateContent\":\n",
        "            print(m.name)\n",
        "print(60*\"-\")\n",
        "\n",
        "print(\"List of models that support embedContent:\\n\")\n",
        "for m in client.models.list():\n",
        "    for action in m.supported_actions:\n",
        "        if action == \"embedContent\":\n",
        "            print(m.name)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3pcJt9NwfNRJ"
      },
      "source": [
        "En Business Analytics, usamos generateContent para el Front-end (hablar con el cliente) y embedContent para el Back-end (encontrar el albar√°n correcto en una base de datos de 1 mill√≥n).\n",
        "\n",
        "- **A. generateContent: El modelo \"Hablador\".**\n",
        "\n",
        "Este es el que usas para el triaje de tickets que vimos en otra Sesi√≥n. Recibe un texto y genera una respuesta basada en su entrenamiento.\n",
        "\n",
        "Ejemplo de uso: \"Resume este ticket de soporte y dime si el cliente est√° enfadado\".\n",
        "\n",
        "- B. **embedContent: El modelo \"Matem√°tico\"**\n",
        "\n",
        "Este modelo convierte el texto en un Vector (un punto en un mapa de miles de dimensiones).\n",
        "\n",
        "Si dos frases tienen vectores cercanos, es que significan lo mismo, aunque usen palabras distintas.\n",
        "\n",
        "Ejemplo de negocio: Si un cliente busca \"mi paquete no llega\" y otro busca \"retraso en el env√≠o\", los embeddings detectar√°n que ambos puntos est√°n en la misma zona del mapa."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RAOHhYceeSUf",
        "outputId": "95e81ba4-bf1c-4f9d-f5f5-348cbc343671"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "AI finds patterns in data to make predictions."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response = client.models.generate_content(\n",
        "    model=\"gemini-3-flash-preview\",\n",
        "    contents=\"Explain how AI works in a few words\",\n",
        ")\n",
        "\n",
        "#Convirtiendo a Markdown\n",
        "from IPython.display import Markdown\n",
        "Markdown(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgq6wwSBjz_B"
      },
      "source": [
        "Los modelos de Gemini suelen tener habilitada la \"reflexi√≥n\" de forma predeterminada, lo que permite que el modelo razone antes de responder a una solicitud.\n",
        "\n",
        "Cada modelo admite diferentes configuraciones de pensamiento, lo que te brinda control sobre el costo, la latencia y la inteligencia."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 959
        },
        "id": "hPekcj1Bj0-h",
        "outputId": "9059c956-2188-4954-bab4-a2d8f4c92b3b"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "At its simplest level, Artificial Intelligence (AI) does not \"think\" the way a human does. Instead, it **finds patterns in massive amounts of data** and uses those patterns to make predictions or decisions.\n",
              "\n",
              "Here is a breakdown of how it works, from the basic building blocks to the complex systems we see today.\n",
              "\n",
              "---\n",
              "\n",
              "### 1. The Core Ingredients: Data and Algorithms\n",
              "To build an AI, you need two main things:\n",
              "*   **Data:** This is the \"fuel.\" It can be text, images, sensor readings, or numbers. For example, to teach an AI to recognize a cat, you show it millions of photos of cats.\n",
              "*   **Algorithms:** These are the \"engines.\" An algorithm is a set of mathematical rules or instructions that tells the computer how to analyze the data.\n",
              "\n",
              "### 2. Machine Learning (The \"Learning\" Part)\n",
              "Traditional computer programs follow \"If-Then\" logic (e.g., *If the user clicks this button, then open this file*). \n",
              "\n",
              "**Machine Learning** is different. Instead of a human writing every rule, we give the computer an algorithm and a lot of data, and the computer **writes its own rules.** \n",
              "*   **Training:** You feed the system data (like chess games). It tries to predict the next move.\n",
              "*   **Feedback:** If it gets it wrong, the algorithm adjusts its internal math to do better next time.\n",
              "*   **Inference:** Once trained, you give it a new problem it has never seen before, and it uses its \"experience\" to provide an answer.\n",
              "\n",
              "### 3. Neural Networks (The Structure)\n",
              "Modern AI (like ChatGPT or Midjourney) uses a specific type of machine learning called **Deep Learning**, which is inspired by the human brain.\n",
              "*   It consists of layers of \"neurons\" (mathematical functions).\n",
              "*   Data enters the first layer, is processed, and passes to the next.\n",
              "*   Each layer looks for something specific. In image recognition, the first layer might find lines, the second layer finds shapes (circles), and the third finds features (eyes or ears).\n",
              "\n",
              "### 4. How Modern AI (like ChatGPT) Works\n",
              "The AI you interact with today is usually a **Large Language Model (LLM)**. It works on the principle of **probability.**\n",
              "*   When you ask ChatGPT a question, it isn‚Äôt \"looking up\" the answer in a database.\n",
              "*   It is calculating, word by word, what the most likely next word should be based on all the text it has ever read. \n",
              "*   *Example:* If you type \"The cat sat on the...\", the AI‚Äôs math tells it there is an 80% chance the next word is \"mat\" and a 1% chance it is \"refrigerator.\"\n",
              "\n",
              "### 5. The Three Main Types of Learning\n",
              "How do we actually get the AI to learn the data?\n",
              "1.  **Supervised Learning:** Like a student with a teacher. You give the AI \"labeled\" data (e.g., a photo labeled \"Dog\"). It learns to associate the label with the image.\n",
              "2.  **Unsupervised Learning:** The AI is given raw data and told to find its own patterns. (e.g., \"Look at these 1 million customers and group them into five types based on their shopping habits.\")\n",
              "3.  **Reinforcement Learning:** Like training a dog with treats. The AI performs a task, and if it does it well, it gets a \"point.\" If it fails, it loses a point. This is how AI learns to play video games or drive cars.\n",
              "\n",
              "### 6. What AI is NOT\n",
              "*   **It isn't conscious:** It doesn't have feelings, beliefs, or desires. It is a very sophisticated calculator.\n",
              "*   **It doesn't \"know\" facts:** It knows *patterns*. This is why AI sometimes \"hallucinates\" (confidently states things that are false)‚Äîit is simply following a mathematical pattern that looks correct but isn't grounded in reality.\n",
              "\n",
              "### Summary\n",
              "AI works by **taking in massive amounts of data**, using **math (algorithms)** to identify patterns in that data, and then **applying those patterns** to new situations to solve problems, generate text, or recognize objects."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from google.genai import types\n",
        "response = client.models.generate_content(\n",
        "    model=\"gemini-3-flash-preview\",\n",
        "    contents=\"How does AI work?\",\n",
        "    config=types.GenerateContentConfig(\n",
        "        thinking_config=types.ThinkingConfig(thinking_level=\"low\")\n",
        "    ),\n",
        ")\n",
        "#Convirtiendo a Markdown\n",
        "from IPython.display import Markdown\n",
        "Markdown(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01zD02dJkoMM"
      },
      "source": [
        "Puedes guiar el comportamiento de los modelos de Gemini con instrucciones del sistema. Para ello, pasa un objeto GenerateContentConfig."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "JtWwYRFSj-QB",
        "outputId": "46b56e3d-2444-43cc-ca1b-18932a3d4bae"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'Markdown' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3314158626.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m )\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mMarkdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'Markdown' is not defined"
          ]
        }
      ],
      "source": [
        "from google.genai import types\n",
        "response = client.models.generate_content(\n",
        "    model=\"gemini-3-flash-preview\",\n",
        "    config=types.GenerateContentConfig(\n",
        "        system_instruction=\"You are a cat. Your name is Neko.\"),\n",
        "    contents=\"Hello there\"\n",
        ")\n",
        "#Convirtiendo a Markdown\n",
        "from IPython.display import Markdown\n",
        "Markdown(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3IhUrE_NlEU2"
      },
      "source": [
        "El objeto GenerateContentConfig tambi√©n te permite reconfigurar los par√°metros de generaci√≥n predeterminados, como la temperatura."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "55fms_KRlFUU"
      },
      "outputs": [],
      "source": [
        "from google.genai import types\n",
        "response = client.models.generate_content(\n",
        "    model=\"gemini-3-flash-preview\",\n",
        "    contents=[\"Explain how AI works\"],\n",
        "    config=types.GenerateContentConfig(\n",
        "        temperature=0.1\n",
        "    )\n",
        ")\n",
        "#Convirtiendo a Markdown\n",
        "from IPython.display import Markdown\n",
        "Markdown(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mh_rbSqYlm6M"
      },
      "source": [
        "La API de Gemini admite entradas multimodales, lo que te permite combinar texto con archivos multimedia. En el siguiente ejemplo, se muestra c√≥mo proporcionar una imagen:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 559
        },
        "id": "kbStinjgloRc",
        "outputId": "e9d2b229-8fc1-48c3-9b45-c1e4755ac48c"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "A detailed Spanish delivery note or sales receipt (albar√°n) from \"COMPANY NAME\" (Jos√© L√≥pez) to Luisa Fernandez, dated 02/01/2020 with the number AL-2020-0002. The document lists charges for local rental, a deposit for a business premises, a 3-month guarantee deposit, and a key right. Each item includes a 5% discount, with a 21% IVA (VAT) applied. The summary at the bottom calculates the taxable base (Base Imponible), total IVA, and a 19% withholding tax (Retenci√≥n), resulting in a final total of 3.149,26 ‚Ç¨. The document features a clean layout on a light pink background."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from google import genai\n",
        "from google.genai import types\n",
        "\n",
        "#ruta_archivo = \"content/alb1.png\" # Para entorno Colab\n",
        "ruta_archivo = \"C:/tlsi/UCV_ML_COURSE/img/alb1.png\" # Para entorno local, colocar la ruta correcta\n",
        "\n",
        "with open(ruta_archivo, 'rb') as f:\n",
        "    image_bytes = f.read()\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model='gemini-2.5-flash',\n",
        "    contents=[\n",
        "      types.Part.from_bytes(\n",
        "        data=image_bytes,\n",
        "        mime_type='image/jpeg',\n",
        "      ),\n",
        "      'Caption this image.'\n",
        "    ]\n",
        "  )\n",
        "\n",
        "#Convirtiendo a Markdown\n",
        "from IPython.display import Markdown\n",
        "Markdown(response.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.13 (googleApi)",
      "language": "python",
      "name": "googleapi"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
